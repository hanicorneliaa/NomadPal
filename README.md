# NomadPal
Helping remote students in low-connectivity areas access personalized, AI-powered learning and Q&amp;A, completely offline, using a lightweight local language model and user-friendly interface.

![NomadPal: Self-hosted LLM](./gui.png)


## ğŸ› ï¸ Tools Used

1. **[Ollama](https://ollama.com/)** â€“ Local LLM model serving backend
2. **[FastAPI](https://fastapi.tiangolo.com/)** â€“ High-performance backend API framework for serving model inference
3. **[Gradio](https://gradio.app/)** â€“ User-friendly graphical interface for interacting with the models
4. **Docker** [**Coming Soon**] â€“ Containerization for simplified deployment and scalability
5. **Database** [**Coming Soon**] â€“ Store and retrieve previous inference results for persistence

---

## ğŸš€ Features

- Serve LLMs locally using Ollama
- API access to model responses via FastAPI
- Interactive UI for testing and experimentation using Gradio
- Modular design for easy extensions
- Docker support coming soon
- Database integration planned for saving/loading session history

---

## âš™ï¸ Installation

[**Coming Soon**]